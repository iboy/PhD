{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf320
{\fonttbl\f0\fmodern\fcharset0 CourierNewPSMT;}
{\colortbl;\red255\green255\blue255;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\ql\qnatural\pardirnatural

\f0\fs36 \cf0 *Digital Puppetry* is a hybrid art form that presently includes a broad range of work and creative practices:\
\
* live *real-time* animation and performance capture processes\
\
* rendered computer generated animation process, referring to animation performance systems, like Pixar Studio's *Marionette* software\
\
* automata and kinetic art practice, involving servo/microprocessor controlled automata, e.g. the art of Ken Feingold[^ChQCVidKenFeingold]\
\
* live multimedia performance \
\
* user-controlled characters in animations or *machinima*, often made with Adobe's *Flash*, game engines or Linden Lab's *Second Life*.\
\
[^ChQCVidKenFeingold]: Ken Feingold [http://www.kenfeingold.com/](http://www.kenfeingold.com/)\
\
When comparing digital puppetry to tradition forms, discussion often involves (i) the distance between the performer and the physical or virtual object and (ii) how the performer is embodied within the physical or virtual object. In the current work, I compose a wirelessly controllable on-screen object using video-graphic elements of a performer (their mouth and eyes) that are reconfigured in real-time into a new image. The same performer can then control the orientation and expressive motion of the speaking image/avatar. I am interested in making virtual objects speak and ask: how does a visual image of a speaking mouth embed the performer in the puppet and create the perception of an expressive living character?\
\
The performance piece, *Of Minnie the Moocher and Me*, had a central visual idea that combined a real-time chroma-keyed mouth and interactive pre-recorded video of eyes. Through movement and reconfiguration, I believed these abstracted facial elements could form a coherent expressive system for a digital puppet (see [][#fig:figure_001_composite]). Add to this real-time vocalisation and synchronised speech, gestural object control using a Nintendo *Wii Remote*[^ChQCWiiRemote], MIDI controlled sequencing of scenography and special effects using foot-switches and a control deck, and I may have a new -- low cost -- approach to digital puppet performance and capture.\
\
[^ChQCWiiRemote]: Wii-Remote Controller: [http://wii.nintendo.com/controller.jsp](http://wii.nintendo.com/controller.jsp)\
\
![fig:figure_001_composite][]\
[fig:figure_001_composite]: figure_001_composite "Composite of real-time mouth, recorded eyes and digital scenography" width=418px height=314px\
\
For visual reference, I turned to American popular culture and a number of out of copyright (public domain) animation forms. I have always had a love of the Fleischer brothers' cartoons of the 1920s and 1930s. Mainly famous for creating *Betty Boop*, *Popeye* and the *Out of the Ink Pot* clown, the Fleischers  are less well known for creating *rotoscoping* -- a technique of painting inks on cells over a mechanism projecting film -- basically tracing film in order to create animation. They established the technique by tracing the performance of one of my favourite jazz singers,  Cab Calloway. In *Snow White* (1933)[^chQCSnowWhite], preceding Walt Disney's version of *Snow White* by a number of years, Calloway sang *Saint James Infirmary* -- a mourning/blues song -- and created an enduring stylistic affinity between early animation and jazz.\
\
[^chQCSnowWhite]: The Fleischer Studios *Snow-White* (1933) See:\\\\ [http://www.imdb.com/title/tt0024578/](http://www.imdb.com/title/tt0024578/)\
\
![fig:figure_002_cab_roto][]\
[fig:figure_002_cab_roto]: figure_002_cab_roto "Rotoscoping in the Fleischer brothers' `Snow White' (1933). Image generated using a `Quartz Composer' composition by Ian Grant" width=418px height=314px\
\
[][#fig:figure_002_cab_roto] depicts the opening and mid-point sequences from the Fleischers' `Snow White' (1933) and illustrates the live-footage moments and the final animated *rotoscoped* sequence.\
\
It is with the same spirit of technological innovation that I aimed to explore similar material with contemporary technology. I aimed to create a real time performance system where I create and control a video based digital character that sings the song, *Minnie the Moocher* by Cab Calloway. I aimed to create the following:\
\
* A performance control system using Apple's *Quartz Composer*[^ChQCQC], a general purpose MIDI controller and a wireless game controller, the Nintendo *Wii-Remote*.\
\
[^ChQCQC]: Apple's *Quartz Composer:*\\\\ [http://developer.apple.com/graphicsimaging/quartz/quartzcomposer.html](http://developer.apple.com/graphicsimaging/quartz/quartzcomposer.html)\
\
* A video processing/projection system with instant chroma-keying of a blue faced performer.\
\
* Some nifty realtime effects, transitions and visual compositions, i.e. elegant digital scenography -- illustrated in [][#fig:figure_007_full_title] -- [][#fig:figure_013_3D_Scene_03] below.\
\
* To work towards a fuller expanded performance telling the extended saga of *Minnie the Moocher*.\
\
\
\
}